---
layout: post
title: 每天10分钟系列之 --- 了解HDFS
image: /img/hello_world.jpeg
date:  2016-05-20 23:00:00 +0800  
description: 开发工具
img: post-9.jpg # Add image post (optional)
tags: [arc]
labels: [hdfs, 每天10分钟]
author: # Add name author (optional)
arc: true
---

### HDFS介绍
- HDFS, 顾名思义为Hadoop分布式文件系统，`是一种可商用的高可靠度的分布式文件系统`，设计用于部署在廉价机器硬件上运行，HDFS具有高度容错能力(HDFS复制数据可以实现这个特点)，

- 旨在部署在低成本硬件上。HDFS提供对应用程序数据的高吞吐量访问，适用于具有大型数据集的应用程序。 

- HDFS是为`存储在集群上运行的文件存储系统`,旨在从单台服务器扩展到数千台计算机，每台计算机都提供本地计算和存储。库本身被设计用来在软件层面检测和处理故障，在集群之上提供高可用性服务。

- HDFS 最初是作为Apache Nutch网络搜索引擎项目的基础架构而构建的。HDFS现在是Apache Hadoop 子项目。 源自于Google的GFS论文，发表于2003年，是GFS的克隆版。


### HDFS 设计的目标
- 非常巨大的分布式文件系统
    - 万个以上节点，亿个文件以上，10pb的容量以上
- 运行在普通廉价的硬件上
    - 文件复制多份、避免硬件失败
    - 探测失败和错误恢复
- 优化批处理
    - 数据暴露位置，以便计算能够挪到数据附件
    - 提供高聚合的带宽
- 用户空间可以位于异构的操作系统中
- 在整个集群中使用单一的命名空间
- 易扩展、为用户提供性能不错的文件系统服务


### HDFS 数据计算特点
- 数据一致性
    - `写入一次读取多次` 的访问模型
    - 客户端只能`追加`已有的文件
- 文件被分为各个小块
    - 默认每块为64M
    - 每一块复制到不同的DataNode上
- 智能的客户端
    - 客户端能找到文件块的位置
    - 客户端能直接访问DataNode中的文件位置
- 程序采用"数据就近" 原则分配节点执行
- 客户端对文件没有缓存机制（no Data caching)

### HDFS 不擅长方面
- 低延迟数据访问
    - 比如毫秒级
    - 低延迟与高吞吐率
- 小文件存取
    - 占用NameNode大量内存
    - 寻道时间超过读取时间
- 并发写入、文件随机修改
    - 一个文件只能有一个写者
    - 仅支持append


### HDFS 架构

![hdfs架构图](http://p6jsga0vv.bkt.clouddn.com/18-11-7/28745451.jpg)

- HDFS 是一个Master(NameNode/NN)/Slave(DataNode/DN) , 一个master带多个Slaves 架构。
- 一个文件会被拆分成多个Block(BlockSzie, 按照大小拆分)，存放多节点。
- NameNode:
    - 负责客户端请求的响应
    - 负责元数据（文件名称，副本系数，Block存放的DataNode)的管理
    - 管理副本的复制

- DataNode:
    - 存储用户的文件对应的数据块（Block)
    - 要定期向NameNode发送心跳信息，汇报本身及其所有的block信息，健康状况
    - 一个NameNode多个DataNode, 生产建议NameNode和DataNode部署在不同的机器上。
- 元数据
    - 用于描述要素，数据集或数据集系列的内容，覆盖范围，质量，管理方式，数据的所有者，数据的提供方式等有关的信息。更简单的说，是关于数据的数据。



![存储方式](http://p6jsga0vv.bkt.clouddn.com/18-11-7/60203619.jpg)

ps 磁盘存储数据是按照数据块来存储的，数据块是磁盘读写最小单位。数据块也称为磁盘块，`在单个文件系统中，小于磁盘块的文件会占用整个磁盘块`, 磁盘块的大小一般是512字节。

- 在hdfs中，也有块的概念（block）, 默认为64MB，每个块作为独立的存储单元。`HDFS中每个小于块大小的文件不会占据整个块的空间`。

##### 为什么是64MB 或 128MB?
- 在hadoop1.x 的HDFS默认块大小为64MB, 在hadoop2.x的默认大小为128MB. 一是解决数据搜索时间，一是mapper可以一次性处理一个块的数据。

- 在文件系统中，系统存储文件时，需要定位到该数据在磁盘中的位置，再进行传输处理， `定位在磁盘的位置是需要时间的`，`文件传输也是需要时间的`。

    T(存储时间)=T(定位时间)+T(传输时间)

    如果每个要传输的块设置得足够大，那么从磁盘传输数据的时间可以明显大于定位这个块开始位置的时间

    T(存储时间)=T(定位时间) )[-∞]+T(传输时间)[∞]

    近似等于：T(存储时间)=T(传输时间)


- 这样设计使存储一个文件主要时间就花在传输过程中，块大小决定传输由多个块组成文件的存储速率，这也是HDFS的核心技术。

### HDFS 操作
我们可以通过编程或命令的方式跟文件系统进行交互。

- hdfs文件系统与Linux文件系统有诸多相似之处。 所以可以将本地文件系统的所有命令操作都用于到HDFS文件系统操作中，比如创建一个路径，复制一个文件，更改权限等等。

- 它也可以控制权限，例如给不同的用户，不同的分组，创建不同的读写权限。

#### 读操作
- 客户端读取一个文件的时候，client 需要和NameNode节点进行交互，因为它是唯一存储数据节点元数据的节点。NameNode规定DataNode点的存储数据的地址跟位置。客户端通过NameNode找到它需要数据的节点，然后直接在找到DataNode中进行读操作。考虑到安全和授权的目的，NameNode给客户端提供token，这个token需要出示给DateNote进行验证，认证通过后，才可以直接从DataNode读取文件。`如果在读取数据期间datanode突然废了，这个客户端会继续访问NameNode,这是NameNode会给出这个数据节点副本的所在位置`。

#### 写操作
- 写文件也需要client和NameNode进行交互。NameNode需要提供可供写入数据的DataNode节点的地址。然后客户端跟特定的DataNode进行交互，将数据直接写进去，直到完成拥有3个副本。`每一个Block至少拷贝到3个相互独立的硬件上，这样能够高速恢复损坏的数据`,当复制完成后，它会给client发送一个通知。写入文件并不十分消耗系统资源，因为它可以在多个数据点将blocaks平行写入。



### 总结
- HDFS 提供给MapReduce数据服务，一般MapREduce的Map任务通常一次处理一个块中的数据，如果任务数太少（少于集群中节点的数量），就没有发挥多节点的优势，甚至作业的运行速度就会和点节点一样。

- 分布式文件抽象带来的优势：
    - 一个文件可以大于每个磁盘
    - 文件不用全在一个磁盘上
    - 简化了存储子系统的设计
    - 基于元数据块的存储方式非常适合用于备份，利用备份可提供数据容错能力和可用性。

{: .box-note}
**Note:** 本文非作为商业用途，侵删. 如果你遇到任何问题，欢迎下面留言哈！ 整理不易，欢迎打赏！
