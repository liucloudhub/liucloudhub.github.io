---
layout: post
title: 每天10分钟系列之 --- 了解Spark与Hadoop
image: /img/hello_world.jpeg
date:  2016-10-01 19:00:00 +0800  
description: 开发工具
img: post-9.jpg # Add image post (optional)
tags: [arc]
labels: [Spark, Hadoop , 每天10分钟]
author: # Add name author (optional)
arc: true
---
###  Spark 简介

- spark 是基于内存计算的大数据并行计算框架,基于java编写。Spark基于内存计算，提高了在大数据环境下数据的实时性，同时保证了高容错性和可伸缩性，允许用户将Spark部署在大量的廉价硬件之上，形成集群。


#### Spark的诞生

- Spark诞生与加州大学伯克利分校，旨在one stack to rule them all, 也就是一套软件栈内完成各种数据分析任务。

- Spark 是MapReduce的替代方案，而且兼容HDFS, Hive等分布式存储层，可融入Hadoop的生态系统，以弥补缺少MapReduce的不足。

### Spark 与 MapReduce 相比的优势

- 中间结果输出
    - 基于MapReduce的计算引擎通常会将中间结果输出到磁盘，进行存储和容错。出于任务管道承接的考虑，当一些查询使用MR 时，往往会产生多个Stage, 而这些串联的Stage又依赖于底层文件系统（如HDFS)来存储每一个Stage的输出结果。 
     
    而Spark将执行模型抽象为通用的有向无环图执行计划(DAG)， 这可以将多Stage的任务串联或者并行执行，而无须将Stage中间结果输出到HDFS中。 

- 数据格式和内存布局

    - Spark 抽象出分布式内存存储结构弹性分布式数据集RDD, 进行数据的存储。 RDD能支持粗粒度写操作，但对于读取操作，RDD可以精确到每条记录，这使得RDD可以用来作为分布式索引。
    
    spark的特性是能够控制数据在不同节点上的分区，用户可以自定义分区策略，如Hash分区等，Spark和Spark SQL 在Spark的基础上实现了列存储和列存储压缩。

- 执行策略
    
    - Spark任务在shuffle中不是所有情景都需要排序，所以支持基于Hash的分布式聚合，调度中采用更为通用的任务执行计划图（DAG)，每一轮次的输出结果在内存缓存

- 任务调度的开销
    
    - 传统的MapReduce 系统，是为了运行长达数小时的批量作业而设计的，在某些极端的情况小，提交一个任务的延迟非常高
    
    - Spark采用了事件驱动的类库AKKA来启动任务，通过线程池复用线程来避免线程或线程启动和切换开销。


### 与Hadoop对比

![](http://p6jsga0vv.bkt.clouddn.com/18-11-10/31313739.jpg)

Hadoop是apache 基金会下的一个开源分布式计算平台，以Hadopop分布式文件系统（HDFS) 和 MapReduce 分布式计算框架为核心，为用户提供了底层细节透明的分布式基础设施。 HDFS的高容错性，高伸缩性等优点，以及MR的分布式特性，解决了传统高性能单机无法解决的大数据处理问题。

### 流处理框架
- Storm 和 Spark Streaming
    
    - 两者都是分布式，容错的实时计算系统，都是讲数据份成一个个小块的批数据进行数据处理。但也有不同，体现在延迟和容错两个方面。



    1. 处理模型，延迟
        两者的处理模型不一样，
        Storm处理的是每次传入的一个事件，而Spark Streaming 是处理某个时间段窗口内事件流。
        因此，Storm处理一个事件可以到达秒内的延迟，而Spark Streaming 则有秒级延迟。

####

    2. 容错、数据保证
        Streaming提供了更好的容错状态计算。
        而Storm能够保证每个记录至少被处理一次，但是在从错误中恢复过来的时候允许出现重复记录。
        这意味着可变状态可能被错误的更新两次。


####

    简而言之，如果需要毫秒级的延迟，Strom 是一个不错的选择，而且没有数据丢失。
    如果需要有状态的计算，技术按延时是秒级，Streaming则更好， 编程逻辑也可能更容易。
    

### Spark 生态系统
Spark设计目的是全栈式解决批处理、结构化数据查询、流计算、图计算和机器学习业务场景，此外其通用性还体现在对存储层(HDFS、cassandra)和资源管理层(MESOS、YARN)的支持。


    存储层
    HDFS：Hadoop Distributed File System
    cassandra：最初由Facebook开发的分布式NoSQL数据库，于2008年开源。

###

    资源管理层
    MESOS：AMPLab最初开发的一个集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享。
    YARN：是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统。
    
![](http://p6jsga0vv.bkt.clouddn.com/18-11-10/29438843.jpg)

### Spark的数据存储
Spark本身是基于内存计算的架构，数据的存储也主要分为内存和磁盘两个路径，Spark本身则根据存储位置、是否可序列化和副本数目这几个要素将数据存储分为多种存储级别。此外还可选择使用Tachyon来管理内存数据。

为了适应迭代计算，Spark将经常被重用的数据缓存到内存中以提升数据读取速度，当内存容量有限的时候则将数据存入磁盘中或根据最近最少使用页面置换算法（Least Recently Used，LRU）算法将内存中使用频率较低的文件空间收回，从而让新的数据进来

### 总结

作为Spark生态系统的核心，Spark主要提供基于内存计算的功能，不仅包含Hadoop的计算模型的MapReduce，还包含很多其他的如reduceByKey、groupByKey、foreach、join和filter等API。
Spark将数据抽象为弹性分布式数据集，有效扩充了Spark编程模型，能让Spark成为多面手，能让交互式查询、流处理、机器学习和图计算的应用无缝交叉融合，极大的扩张了Spark的应用业务场景，同时Spark使用函数式编程语言Scala，让编程更简洁高效。


### 参考资料
- [spark官网](http://spark.apache.org/)

{: .box-note}
**Note:** 本文非作为商业用途，侵删. 如果你遇到任何问题，欢迎下面留言哈！ 整理不易，欢迎打赏！
